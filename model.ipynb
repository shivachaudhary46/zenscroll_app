{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fd408f",
   "metadata": {},
   "source": [
    "# Toxicity Classification\n",
    "\n",
    "1. #### Problem Defination \n",
    "\n",
    "        When person sees negative comments about themselves. They feel suffocated, deppressesd, anxiety hit them. so, to solve this problem and encourage people to give positive comments, me and my team is creating the toxicity classifier which can classifies negative, positive words and comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a7a67",
   "metadata": {},
   "source": [
    "2. #### Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c03fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\zenscroll_app\n"
     ]
    }
   ],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd \n",
    "import os \n",
    "from bs4 import BeautifulSoup\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk \n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import html\n",
    "import unicodedata\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae204bf1",
   "metadata": {},
   "source": [
    "3. #### finding and reading the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f43d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset/train/train.csv\", encoding=\"utf-8\")\n",
    "test = pd.read_csv(\"dataset/test/test.csv\",  encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869f3190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1804874 entries, 0 to 1804873\n",
      "Data columns (total 45 columns):\n",
      " #   Column                               Dtype  \n",
      "---  ------                               -----  \n",
      " 0   id                                   int64  \n",
      " 1   target                               float64\n",
      " 2   comment_text                         object \n",
      " 3   severe_toxicity                      float64\n",
      " 4   obscene                              float64\n",
      " 5   identity_attack                      float64\n",
      " 6   insult                               float64\n",
      " 7   threat                               float64\n",
      " 8   asian                                float64\n",
      " 9   atheist                              float64\n",
      " 10  bisexual                             float64\n",
      " 11  black                                float64\n",
      " 12  buddhist                             float64\n",
      " 13  christian                            float64\n",
      " 14  female                               float64\n",
      " 15  heterosexual                         float64\n",
      " 16  hindu                                float64\n",
      " 17  homosexual_gay_or_lesbian            float64\n",
      " 18  intellectual_or_learning_disability  float64\n",
      " 19  jewish                               float64\n",
      " 20  latino                               float64\n",
      " 21  male                                 float64\n",
      " 22  muslim                               float64\n",
      " 23  other_disability                     float64\n",
      " 24  other_gender                         float64\n",
      " 25  other_race_or_ethnicity              float64\n",
      " 26  other_religion                       float64\n",
      " 27  other_sexual_orientation             float64\n",
      " 28  physical_disability                  float64\n",
      " 29  psychiatric_or_mental_illness        float64\n",
      " 30  transgender                          float64\n",
      " 31  white                                float64\n",
      " 32  created_date                         object \n",
      " 33  publication_id                       int64  \n",
      " 34  parent_id                            float64\n",
      " 35  article_id                           int64  \n",
      " 36  rating                               object \n",
      " 37  funny                                int64  \n",
      " 38  wow                                  int64  \n",
      " 39  sad                                  int64  \n",
      " 40  likes                                int64  \n",
      " 41  disagree                             int64  \n",
      " 42  sexual_explicit                      float64\n",
      " 43  identity_annotator_count             int64  \n",
      " 44  toxicity_annotator_count             int64  \n",
      "dtypes: float64(32), int64(10), object(3)\n",
      "memory usage: 619.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaeea65",
   "metadata": {},
   "source": [
    "4. #### Data Preprocessing (Text Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "260552c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # removing stop words from text s\n",
    "    stop = set(stopwords.words('english'))\n",
    "    # updating the text with punctuation to make new line. \n",
    "    stop.update(list(string.punctuation))\n",
    "\n",
    "    # Remove unwanted html characters\n",
    "    remove_html_chars = re.compile(r'  +')\n",
    "    replace_char = text.lower().replace('#39;', \"'\")\\\n",
    "                .replace('amp;', '&').replace('#146;', \"'\")\\\n",
    "                .replace('nbsp;', ' ').replace('#36;', '$')\\\n",
    "                .replace('\\\\n', \"\\n\").replace('quot;', \"'\")\\\n",
    "                .replace('<br />', \"\\n\").replace('\\\\\"', '\"')\\\n",
    "                .replace('<unk>', 'u_n').replace(' @.@ ', '.')\\\n",
    "                .replace(' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    text = remove_html_chars.sub(' ', html.unescape(replace_char))\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # remove between square characters \n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "    # remove URLs \n",
    "    text = re.sub(r'https://\\S+', '', text)\n",
    "\n",
    "    # remove tags \n",
    "    text = text.replace(\"@\", \"\")\n",
    "\n",
    "    # remove hashtags\n",
    "    text = text.replace(\"#\", '')\n",
    "\n",
    "    # remove all non alphaetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # replace underscores\n",
    "    text = text.replace(\"_\", \" \")\n",
    "\n",
    "    # replace - \n",
    "    text = text.replace('-', ' ')\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # remove stopwords \n",
    "    stopped_words = [word for word in tokens if word not in stop]\n",
    "\n",
    "    # converting the words to base by removing the suffixes\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stopped_words]\n",
    "    clean_text = \" \".join(lemmatized_words)\n",
    "\n",
    "    return clean_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3737536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negation match single character setofcharacters default match casesensitiveexample match character except abc'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"10. [^set_of_characters] Negation: \\\n",
    "Matches any single character that is not in set_of_characters. By default, the match is case-sensitive.\\\n",
    "Example : [^abc] will match any character except a,b,c .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d7ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
